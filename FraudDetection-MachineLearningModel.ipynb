{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f122af4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    precision_recall_curve,\n",
    "    auc\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d2e65bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Obtaining dependency information for imbalanced-learn from https://files.pythonhosted.org/packages/65/60/103dc71019ec2fa987f42f9dbe88641a74edc57f8499fac8896955b66065/imbalanced_learn-0.14.0-py3-none-any.whl.metadata\n",
      "  Downloading imbalanced_learn-0.14.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.25.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy<2,>=1.11.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.4.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: joblib<2,>=1.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (3.6.0)\n",
      "Downloading imbalanced_learn-0.14.0-py3-none-any.whl (239 kB)\n",
      "   ---------------------------------------- 0.0/240.0 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/240.0 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/240.0 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/240.0 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 30.7/240.0 kB 163.8 kB/s eta 0:00:02\n",
      "   ------ -------------------------------- 41.0/240.0 kB 163.4 kB/s eta 0:00:02\n",
      "   --------- ----------------------------- 61.4/240.0 kB 233.8 kB/s eta 0:00:01\n",
      "   -------------- ------------------------ 92.2/240.0 kB 308.0 kB/s eta 0:00:01\n",
      "   ----------------- -------------------- 112.6/240.0 kB 312.2 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 153.6/240.0 kB 382.3 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 225.3/240.0 kB 509.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- 240.0/240.0 kB 489.8 kB/s eta 0:00:00\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.14.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ef8e5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57421946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  transaction_id customer_id       card_number  \\\n",
      "0    TX_a0ad2a2a  CUST_72886  6646734767813109   \n",
      "1    TX_3599c101  CUST_70474   376800864692727   \n",
      "2    TX_a9461c6d  CUST_10715  5251909460951913   \n",
      "3    TX_7be21fc4  CUST_16193   376079286931183   \n",
      "4    TX_150f490b  CUST_87572  6172948052178810   \n",
      "\n",
      "                          timestamp merchant_category merchant_type  \\\n",
      "0  2024-09-30 00:00:01.034820+00:00        Restaurant     fast_food   \n",
      "1  2024-09-30 00:00:01.764464+00:00     Entertainment        gaming   \n",
      "2  2024-09-30 00:00:02.273762+00:00           Grocery      physical   \n",
      "3  2024-09-30 00:00:02.297466+00:00               Gas         major   \n",
      "4  2024-09-30 00:00:02.544063+00:00        Healthcare       medical   \n",
      "\n",
      "         merchant     amount currency    country  ...   device channel  \\\n",
      "0       Taco Bell     294.87      GBP         UK  ...  iOS App  mobile   \n",
      "1           Steam    3368.97      BRL     Brazil  ...     Edge     web   \n",
      "2     Whole Foods  102582.38      JPY      Japan  ...  Firefox     web   \n",
      "3           Exxon     630.60      AUD  Australia  ...  iOS App  mobile   \n",
      "4  Medical Center  724949.27      NGN    Nigeria  ...   Chrome     web   \n",
      "\n",
      "                 device_fingerprint       ip_address distance_from_home  \\\n",
      "0  e8e6160445c935fd0001501e4cbac8bc   197.153.60.199                  0   \n",
      "1  a73043a57091e775af37f252b3a32af9  208.123.221.203                  1   \n",
      "2  218864e94ceaa41577d216b149722261   10.194.159.204                  0   \n",
      "3  70423fa3a1e74d01203cf93b51b9631d   17.230.177.225                  0   \n",
      "4  9880776c7b6038f2af86bd4e18a1b1a4  136.241.219.151                  1   \n",
      "\n",
      "  high_risk_merchant transaction_hour weekend_transaction  \\\n",
      "0              False                0               False   \n",
      "1               True                0               False   \n",
      "2              False                0               False   \n",
      "3              False                0               False   \n",
      "4              False                0               False   \n",
      "\n",
      "                                  velocity_last_hour  is_fraud  \n",
      "0  {'num_transactions': 1197, 'total_amount': 334...     False  \n",
      "1  {'num_transactions': 509, 'total_amount': 2011...      True  \n",
      "2  {'num_transactions': 332, 'total_amount': 3916...     False  \n",
      "3  {'num_transactions': 764, 'total_amount': 2201...     False  \n",
      "4  {'num_transactions': 218, 'total_amount': 4827...      True  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7483766 entries, 0 to 7483765\n",
      "Data columns (total 24 columns):\n",
      " #   Column               Dtype  \n",
      "---  ------               -----  \n",
      " 0   transaction_id       object \n",
      " 1   customer_id          object \n",
      " 2   card_number          int64  \n",
      " 3   timestamp            object \n",
      " 4   merchant_category    object \n",
      " 5   merchant_type        object \n",
      " 6   merchant             object \n",
      " 7   amount               float64\n",
      " 8   currency             object \n",
      " 9   country              object \n",
      " 10  city                 object \n",
      " 11  city_size            object \n",
      " 12  card_type            object \n",
      " 13  card_present         bool   \n",
      " 14  device               object \n",
      " 15  channel              object \n",
      " 16  device_fingerprint   object \n",
      " 17  ip_address           object \n",
      " 18  distance_from_home   int64  \n",
      " 19  high_risk_merchant   bool   \n",
      " 20  transaction_hour     int64  \n",
      " 21  weekend_transaction  bool   \n",
      " 22  velocity_last_hour   object \n",
      " 23  is_fraud             bool   \n",
      "dtypes: bool(4), float64(1), int64(3), object(16)\n",
      "memory usage: 1.1+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Admin\\\\Downloads\\\\synthetic_fraud_data.csv\")\n",
    "\n",
    "\n",
    "print(df.head())\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0319bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining features and target\n",
    "target_col = \"is_fraud\"\n",
    "\n",
    "# Drop IDs, sensitive info\n",
    "drop_cols = [\"transaction_id\", \"customer_id\", \"card_number\", \n",
    "             \"timestamp\", \"device_fingerprint\", \"ip_address\", \"merchant\"]\n",
    "\n",
    "X = df.drop(columns=drop_cols + [target_col])\n",
    "y = df[target_col].astype(int)  # convert bool to int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "026dc697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric: ['amount', 'distance_from_home', 'transaction_hour']\n",
      "Categorical: ['merchant_category', 'merchant_type', 'currency', 'country', 'city', 'city_size', 'card_type', 'card_present', 'device', 'channel', 'high_risk_merchant', 'weekend_transaction', 'velocity_last_hour']\n"
     ]
    }
   ],
   "source": [
    "### Separating numeric & categorical features\n",
    "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=[\"object\", \"bool\"]).columns.tolist()\n",
    "\n",
    "print(\"Numeric:\", numeric_features)\n",
    "print(\"Categorical:\", categorical_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50e5019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline\n",
    "numeric_transformer = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8dcca9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Transform features\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b62d3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Handle class imbalance with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_transformed, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e771d1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Logistic Regression (baseline)\n",
    "log_reg = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "log_reg.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred_lr = log_reg.predict(X_test_transformed)\n",
    "y_proba_lr = log_reg.predict_proba(X_test_transformed)[:, 1]\n",
    "\n",
    "print(\"Logistic Regression:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb4298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random Forest Classifier\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test_transformed)\n",
    "y_proba_rf = rf.predict_proba(X_test_transformed)[:, 1]\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054d77a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Precision-Recall Curve for Random Forest\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba_rf)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(recall, precision, label=f'PR-AUC={pr_auc:.4f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed40be56",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Isolation Forest (Anomaly Detection)\n",
    "iso_forest = IsolationForest(\n",
    "    n_estimators=300,\n",
    "    contamination=y.mean(),  # estimated fraud rate\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "iso_forest.fit(X_train_transformed)\n",
    "\n",
    "# Predictions: -1 = anomaly, 1 = normal â†’ map to fraud=1\n",
    "iso_preds = iso_forest.predict(X_test_transformed)\n",
    "iso_preds = np.where(iso_preds == -1, 1, 0)\n",
    "\n",
    "print(\"Isolation Forest:\")\n",
    "print(classification_report(y_test, iso_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e900428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Summary of Model ROC-AUC\n",
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"Logistic Regression\", \"Random Forest\", \"Isolation Forest\"],\n",
    "    \"ROC_AUC\": [\n",
    "        roc_auc_score(y_test, y_proba_lr),\n",
    "        roc_auc_score(y_test, y_proba_rf),\n",
    "        np.nan  # ROC-AUC not meaningful for unsupervised without probabilities\n",
    "    ]\n",
    "})\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77303126",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['velocity_num'] = df['velocity_last_hour'].apply(lambda x: eval(x)['num_transactions'])\n",
    "df['velocity_amount'] = df['velocity_last_hour'].apply(lambda x: eval(x)['total_amount'])\n",
    "X = X.drop(columns=['velocity_last_hour'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
